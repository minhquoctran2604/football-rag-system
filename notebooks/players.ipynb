{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb31e24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df_players = pd.read_csv('data/players_data-2024_2025.csv')\n",
    "for i in df_players.columns:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f345da57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2854, 267)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_players.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c817c8eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rk</th>\n",
       "      <th>Player</th>\n",
       "      <th>Nation</th>\n",
       "      <th>Pos</th>\n",
       "      <th>Squad</th>\n",
       "      <th>Comp</th>\n",
       "      <th>Age</th>\n",
       "      <th>Born</th>\n",
       "      <th>MP</th>\n",
       "      <th>Starts</th>\n",
       "      <th>...</th>\n",
       "      <th>Att (GK)</th>\n",
       "      <th>Thr</th>\n",
       "      <th>Launch%</th>\n",
       "      <th>AvgLen</th>\n",
       "      <th>Opp</th>\n",
       "      <th>Stp</th>\n",
       "      <th>Stp%</th>\n",
       "      <th>#OPA</th>\n",
       "      <th>#OPA/90</th>\n",
       "      <th>AvgDist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Max Aarons</td>\n",
       "      <td>eng ENG</td>\n",
       "      <td>DF</td>\n",
       "      <td>Bournemouth</td>\n",
       "      <td>eng Premier League</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Max Aarons</td>\n",
       "      <td>eng ENG</td>\n",
       "      <td>DF,MF</td>\n",
       "      <td>Valencia</td>\n",
       "      <td>es La Liga</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Rodrigo Abajas</td>\n",
       "      <td>es ESP</td>\n",
       "      <td>DF</td>\n",
       "      <td>Valencia</td>\n",
       "      <td>es La Liga</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>James Abankwah</td>\n",
       "      <td>ie IRL</td>\n",
       "      <td>DF,MF</td>\n",
       "      <td>Udinese</td>\n",
       "      <td>it Serie A</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Keyliane Abdallah</td>\n",
       "      <td>fr FRA</td>\n",
       "      <td>FW</td>\n",
       "      <td>Marseille</td>\n",
       "      <td>fr Ligue 1</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 165 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rk             Player   Nation    Pos        Squad                Comp  \\\n",
       "0   1         Max Aarons  eng ENG     DF  Bournemouth  eng Premier League   \n",
       "1   2         Max Aarons  eng ENG  DF,MF     Valencia          es La Liga   \n",
       "2   3     Rodrigo Abajas   es ESP     DF     Valencia          es La Liga   \n",
       "3   4     James Abankwah   ie IRL  DF,MF      Udinese          it Serie A   \n",
       "4   5  Keyliane Abdallah   fr FRA     FW    Marseille          fr Ligue 1   \n",
       "\n",
       "    Age    Born  MP  Starts  ...  Att (GK)  Thr  Launch%  AvgLen  Opp  Stp  \\\n",
       "0  24.0  2000.0   3       1  ...       NaN  NaN      NaN     NaN  NaN  NaN   \n",
       "1  24.0  2000.0   4       1  ...       NaN  NaN      NaN     NaN  NaN  NaN   \n",
       "2  21.0  2003.0   1       1  ...       NaN  NaN      NaN     NaN  NaN  NaN   \n",
       "3  20.0  2004.0   6       0  ...       NaN  NaN      NaN     NaN  NaN  NaN   \n",
       "4  18.0  2006.0   1       0  ...       NaN  NaN      NaN     NaN  NaN  NaN   \n",
       "\n",
       "   Stp%  #OPA  #OPA/90  AvgDist  \n",
       "0   NaN   NaN      NaN      NaN  \n",
       "1   NaN   NaN      NaN      NaN  \n",
       "2   NaN   NaN      NaN      NaN  \n",
       "3   NaN   NaN      NaN      NaN  \n",
       "4   NaN   NaN      NaN      NaN  \n",
       "\n",
       "[5 rows x 165 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_players_light = pd.read_csv('data/players_data_light-2024_2025.csv')\n",
    "df_players_light.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f154fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# T√¨m top players d·ª±a tr√™n performance\n",
    "df_players = pd.read_csv(\"data/players_data-2024_2025.csv\")\n",
    "\n",
    "# Top performers by goals\n",
    "top_scorers = df_players.nlargest(50, \"Gls\")[[\"Player\", \"Squad\", \"Comp\", \"Gls\", \"Ast\"]]\n",
    "print(\"Top 50 goal scorers:\")\n",
    "print(top_scorers.head(10))\n",
    "\n",
    "# Top players by assists  \n",
    "top_assists = df_players.nlargest(50, \"Ast\")[[\"Player\", \"Squad\", \"Comp\", \"Gls\", \"Ast\"]]\n",
    "print(\"\\nTop 50 assists leaders:\")\n",
    "print(top_assists.head(10))\n",
    "\n",
    "# Top players by market value teams\n",
    "big_teams = [\n",
    "    \"Manchester City\", \"Arsenal\", \"Liverpool\", \"Chelsea\", \"Manchester United\",\n",
    "    \"Real Madrid\", \"Barcelona\", \"Atletico Madrid\", \n",
    "    \"Bayern Munich\", \"Borussia Dortmund\",\n",
    "    \"Juventus\", \"AC Milan\", \"Inter\", \"Napoli\",\n",
    "    \"PSG\", \"Marseille\", \"Monaco\"\n",
    "]\n",
    "\n",
    "top_players_big_teams = df_players[df_players[\"Squad\"].isin(big_teams)]\n",
    "print(f\"\\nPlayers from big teams: {len(top_players_big_teams)}\")\n",
    "\n",
    "# K·∫øt h·ª£p c√°c criteria\n",
    "important_players = pd.concat([\n",
    "    df_players.nlargest(100, \"Gls\"),\n",
    "    df_players.nlargest(50, \"Ast\"), \n",
    "    top_players_big_teams\n",
    "]).drop_duplicates(\"Player\")\n",
    "\n",
    "print(f\"Total important players: {len(important_players)}\")\n",
    "important_player_names = set(important_players[\"Player\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2038731",
   "metadata": {},
   "outputs": [],
   "source": [
    "# v3 football api\n",
    "import requests\n",
    "import time\n",
    "import datetime, json\n",
    "# C·∫•u h√¨nh API-Football\n",
    "API_KEY = \"56fe75b656667fd06e234aaa4952f3b1\"  \n",
    "BASE_URL = \"https://v3.football.api-sports.io\"\n",
    "\n",
    "headers = {\n",
    "    \"x-rapidapi-key\": API_KEY,\n",
    "    \"x-rapidapi-host\": \"v3.football.api-sports.io\"\n",
    "}\n",
    "\n",
    "def get_api_football_data(player_name: str) -> dict:\n",
    "    \"\"\"L·∫•y injury status + transfers cho player\"\"\"\n",
    "    \n",
    "    # 1. T√¨m player ID\n",
    "    search_url = f\"{BASE_URL}/players\"\n",
    "    params = {\"search\": player_name}\n",
    "    response = requests.get(search_url, headers=headers, params=params)\n",
    "    \n",
    "    if response.status_code != 200:\n",
    "        return {\"injury_status\": {\"status\": \"not_found\"}, \"transfers\": []}\n",
    "    \n",
    "    data = response.json()\n",
    "    if not data.get(\"response\"):\n",
    "        return {\"injury_status\": {\"status\": \"not_found\"}, \"transfers\": []}\n",
    "    \n",
    "    player_info = data[\"response\"][0][\"player\"]\n",
    "    player_id = player_info[\"id\"]\n",
    "    \n",
    "    # 2. L·∫•y injury status\n",
    "    injury_url = f\"{BASE_URL}/injuries\"\n",
    "    injury_params = {\"player\": player_id}\n",
    "    injury_response = requests.get(injury_url, headers=headers, params=injury_params)\n",
    "    \n",
    "    injury_status = {\"status\": \"healthy\"}  # default\n",
    "    if injury_response.status_code == 200:\n",
    "        injury_data = injury_response.json()\n",
    "        if injury_data.get(\"response\"):\n",
    "            injury_info = injury_data[\"response\"][0]\n",
    "            injury_status = {\n",
    "                \"status\": \"injured\",\n",
    "                \"type\": injury_info.get(\"player\", {}).get(\"type\", \"unknown\"),\n",
    "                \"reason\": injury_info.get(\"player\", {}).get(\"reason\", \"\"),\n",
    "                \"last_updated\": datetime.now().isoformat()\n",
    "            }\n",
    "    \n",
    "    # 3. L·∫•y transfers (t√≥m t·∫Øt)\n",
    "    transfers = []  # API n√†y c√≥ th·ªÉ c·∫ßn tr·∫£ ph√≠\n",
    "    \n",
    "    time.sleep(0.5)  # Rate limit friendly\n",
    "    return {\n",
    "        \"injury_status\": injury_status,\n",
    "        \"transfers\": transfers\n",
    "    }\n",
    "\n",
    "# Test v·ªõi 5 players quan tr·ªçng\n",
    "important_test = [\"Lionel Messi\", \"Cristiano Ronaldo\", \"Kylian Mbapp√©\", \"Erling Haaland\", \"Vinicius Jr\"]\n",
    "\n",
    "for player in important_test:\n",
    "    print(f\"Getting data for {player}...\")\n",
    "    data = get_api_football_data(player)\n",
    "    print(f\"  Injury: {data['injury_status']['status']}\")\n",
    "    print(f\"  Transfers: {len(data['transfers'])}\")\n",
    "    time.sleep(1)  # Respect rate limit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd216306",
   "metadata": {},
   "source": [
    "## Get Career Stats by Season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a04b469",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import soccerdata as sd\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# L·∫•y d·ªØ li·ªáu 5 m√πa g·∫ßn nh·∫•t c·ªßa 5 gi·∫£i VƒêQG h√†ng ƒë·∫ßu\n",
    "# soccerdata s·∫Ω cache d·ªØ li·ªáu, l·∫ßn ch·∫°y sau s·∫Ω r·∫•t nhanh\n",
    "seasons = [\"23-24\", \"22-23\", \"21-22\", \"20-21\", \"19-20\",\"18-19\", \"17-18\", \"16-17\", \"15-16\", \"14-15\"]\n",
    "try:\n",
    "    fbref = sd.FBref(leagues=\"Big 5 European Leagues Combined\", seasons=seasons)\n",
    "    print(f\"ƒêang t·∫£i d·ªØ li·ªáu stats cho {len(seasons)} m√πa t·ª´ FBref...\")\n",
    "    \n",
    "    # L·∫•y 'standard stats'\n",
    "    stats_df = fbref.read_player_season_stats(stat_type='standard')\n",
    "\n",
    "    # Add helper function ƒë·ªÉ access column safely\n",
    "    def safe_get(row, category, stat, default=0):\n",
    "        col = (category, stat)\n",
    "        value = row.get(col, default)\n",
    "        if pd.isna(value):\n",
    "            return default\n",
    "        return value\n",
    "\n",
    "    # Chuy·ªÉn ƒë·ªïi DataFrame sang dict theo format y√™u c·∫ßu\n",
    "    career_stats_by_name = {}\n",
    "    # Group theo t√™n c·∫ßu th·ªß\n",
    "    for player_name, player_df in stats_df.groupby(level=\"player\"):\n",
    "        career = []\n",
    "        # S·∫Øp x·∫øp theo m√πa, m√πa m·ªõi nh·∫•t l√™n tr∆∞·ªõc\n",
    "        for idx, row in player_df.sort_index(level='season', ascending=False).iterrows():\n",
    "    # idx[0] = league, idx[1] = season, idx[2] = team, idx[3] = player\n",
    "    \n",
    "            season_str = idx[1]  # season t·ª´ index level 1 (nh∆∞ '2324')\n",
    "            season_formatted = f\"20{season_str[:2]}-20{season_str[2:]}\"\n",
    "            \n",
    "            # ‚úÖ FIXED: S·ª≠ d·ª•ng correct column access pattern\n",
    "            season_data = {\n",
    "                \"season\": season_formatted,\n",
    "                \"club\": idx[2],  # team t·ª´ index level 2 ‚úÖ\n",
    "                \"league\": idx[0],  # league t·ª´ index level 0 ‚úÖ\n",
    "                \"matches\": int(safe_get(row, 'Playing Time', 'MP', 0)),\n",
    "                \"starts\": int(safe_get(row, 'Playing Time', 'Starts', 0)),\n",
    "                \"minutes\": int(safe_get(row, 'Playing Time', 'Min', 0)),\n",
    "                \"goals\": int(safe_get(row, 'Performance', 'Gls', 0)),\n",
    "                \"assists\": int(safe_get(row, 'Performance', 'Ast', 0)),\n",
    "                \"xg\": safe_get(row, 'Expected', 'xG', 0.0),\n",
    "                \"xa\": safe_get(row, 'Expected', 'xAG', 0.0),\n",
    "                \"yellow_cards\": int(safe_get(row, 'Performance', 'CrdY', 0)),\n",
    "                \"red_cards\": int(safe_get(row, 'Performance', 'CrdR', 0)),\n",
    "            }\n",
    "            career.append(season_data)\n",
    "        \n",
    "        career_stats_by_name[player_name] = career\n",
    "\n",
    "    print(f\"\\nƒê√£ x·ª≠ l√Ω xong career stats cho {len(career_stats_by_name)} c·∫ßu th·ªß.\")\n",
    "\n",
    "    # In th·ª≠ d·ªØ li·ªáu c·ªßa m·ªôt c·∫ßu th·ªß\n",
    "    if \"Harry Kane\" in career_stats_by_name:\n",
    "        print(\"\\nV√≠ d·ª• career_stats cho 'Harry Kane':\")\n",
    "        print(json.dumps(career_stats_by_name[\"Harry Kane\"], indent=2))\n",
    "\n",
    "    # L∆∞u ra file ƒë·ªÉ cell merge s·ª≠ d·ª•ng\n",
    "    out_path = \"data/career_stats.json\"\n",
    "    with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(career_stats_by_name, f, ensure_ascii=False)\n",
    "    print(f\"\\nƒê√£ l∆∞u career stats v√†o file: {out_path}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"ƒê√£ c√≥ l·ªói x·∫£y ra khi l·∫•y d·ªØ li·ªáu t·ª´ soccerdata: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8d3b88",
   "metadata": {},
   "source": [
    "## Metadata Placeholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579a53e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import unicodedata\n",
    "from datetime import datetime, timezone\n",
    "import wikipediaapi\n",
    "# 1) Load Kaggle players data\n",
    "df_players = pd.read_csv(\"data/players_data-2024_2025.csv\")\n",
    "\n",
    "\n",
    "def norm(s: str) -> str:\n",
    "    s = \"\" if pd.isna(s) else str(s)\n",
    "    s = unicodedata.normalize(\"NFKD\", s).encode(\"ascii\", \"ignore\").decode(\"ascii\")\n",
    "    return \" \".join(s.lower().split())\n",
    "\n",
    "\n",
    "def make_entity_id(row) -> str:\n",
    "    name = norm(row.get(\"Player\", \"unknown\"))\n",
    "    club = norm(row.get(\"Squad\", \"unknown\"))\n",
    "    league = norm(row.get(\"Comp\", \"unknown\"))\n",
    "    base = f\"{name}_{club}_{league}_2024_2025\"\n",
    "    return f\"player_{base.replace(' ', '_')}\"\n",
    "\n",
    "\n",
    "def num(row, col, default=None):\n",
    "    v = row.get(col, default)\n",
    "    try:\n",
    "        if pd.isna(v):\n",
    "            return default\n",
    "        return float(v)\n",
    "    except (TypeError, ValueError):\n",
    "        return default\n",
    "\n",
    "def fetch_wiki_summary(player_name: str) -> str | None:\n",
    "    if not player_name: return None\n",
    "    wiki = wikipediaapi.Wikipedia(\n",
    "        user_agent=\"RAG_Football/1.0 (mqt26094@gmail.com)\",\n",
    "        language=\"en\"\n",
    "    )\n",
    "    page = wiki.page(player_name)\n",
    "    if page.exists():\n",
    "        return page.summary\n",
    "    return \"Unknown\"\n",
    "\n",
    "\n",
    "entities = []\n",
    "now_iso = datetime.now(timezone.utc).isoformat().replace(\"+00:00\", \"Z\")\n",
    "\n",
    "for _, row in df_players.iterrows():\n",
    "    name = row.get(\"Player\", \"\")\n",
    "    nationality = row.get(\"Nation\", \"\")\n",
    "    pos = row.get(\"Pos\", \"\")\n",
    "    club = row.get(\"Squad\", \"\")\n",
    "    league = row.get(\"Comp\", \"\")\n",
    "    biography = fetch_wiki_summary(name)\n",
    "    # Stats m√πa hi·ªán t·∫°i t·ª´ Kaggle cho 24-25\n",
    "    season_stats = {\n",
    "        \"matches\": num(row, \"MP\", 0),\n",
    "        \"starts\": num(row, \"Starts\", 0),\n",
    "        \"minutes\": num(row, \"Min\", 0),\n",
    "        \"full_90s\": num(row, \"90s\", 0),\n",
    "        \"goals\": num(row, \"Gls\", 0),\n",
    "        \"assists\": num(row, \"Ast\", 0),\n",
    "        \"goals_plus_assists\": num(row, \"G+A\", 0),\n",
    "        \"non_penalty_goals\": num(row, \"G-PK\", 0),\n",
    "        \"xg\": num(row, \"xG\"),\n",
    "        \"xa\": num(row, \"xAG\"),\n",
    "        \"yellow_cards\": num(row, \"CrdY\", 0),\n",
    "        \"red_cards\": num(row, \"CrdR\", 0),\n",
    "        # C√°c tr∆∞·ªùng d∆∞·ªõi s·∫Ω ƒë∆∞·ª£c map n·∫øu d√πng b·∫£n full ho·∫∑c ngu·ªìn kh√°c\n",
    "        \"shots\": None,\n",
    "        \"shots_on_target\": None,\n",
    "        \"key_passes\": None,\n",
    "        \"progressive_passes\": None,\n",
    "        \"progressive_carries\": None,\n",
    "        \"tackles\": None,\n",
    "        \"interceptions\": None,\n",
    "    }\n",
    "\n",
    "    # T·∫°m coi 24-25 l√† 1 entry trong career_stats\n",
    "    career_stats = [\n",
    "        {\n",
    "            \"season\": \"2024-2025\",\n",
    "            \"club\": norm(club),\n",
    "            \"league\": norm(league),\n",
    "            **season_stats,\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    entity = {\n",
    "        \"entity_type\": \"player\",\n",
    "        \"entity_id\": make_entity_id(row),\n",
    "        \"name\": norm(name),\n",
    "\n",
    "        \"identity\": {\n",
    "            \"birth_year\": None,          # s·∫Ω fill t·ª´ Sportmonks/API kh√°c\n",
    "            \"nationality\": norm(nationality),\n",
    "            \"position\": norm(pos),\n",
    "            \"height_cm\": None,\n",
    "            \"weight_kg\": None,\n",
    "            \"dominant_foot\": None,\n",
    "        },\n",
    "\n",
    "        \"current_season\": \"2024-2025\",\n",
    "        \"current_club\": norm(club),\n",
    "        \"current_league\": norm(league),\n",
    "\n",
    "        # Stats m√πa hi·ªán t·∫°i (alias ti·ªán d·ª•ng cho truy v·∫•n nhanh)\n",
    "        \"season_stats\": season_stats,\n",
    "\n",
    "        # L·ªãch s·ª≠ theo m√πa (hi·ªán t·∫°i m·ªõi c√≥ 24-25, sau append th√™m t·ª´ worldfootballR/API)\n",
    "        \"career_stats\": career_stats,\n",
    "\n",
    "        \"big5_career_totals\": None,\n",
    "        # T·ªïng h·ª£p s·ª± nghi·ªáp (t√≠nh l·∫°i t·ª´ career_stats khi ƒë√£ ƒë·ªß d·ªØ li·ªáu)\n",
    "        \"career_totals\": {\n",
    "            \"total_career_goals\": None,\n",
    "            \"total_career_assists\": None,\n",
    "            \"total_career_matches\": None,\n",
    "            \"total_career_minutes\": None,\n",
    "        },\n",
    "\n",
    "        \"injury_status\": {\n",
    "            \"status\": \"unknown\",\n",
    "            \"last_injury_date\": None,\n",
    "            \"details\": None,\n",
    "        },\n",
    "\n",
    "        \"biography\": biography,   \n",
    "        \"transfers\": [],     # s·∫Ω fill t·ª´ Transfermarkt/dataset\n",
    "    \n",
    "        \"sources\": [\"kaggle\"],\n",
    "        \"last_updated\": now_iso,\n",
    "    }\n",
    "\n",
    "    entities.append(entity)\n",
    "\n",
    "output_path = \"data/players_metadata_placeholder_2024_2025.jsonl\"\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    for e in entities:\n",
    "        f.write(json.dumps(e, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "len(entities)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a125b4",
   "metadata": {},
   "source": [
    "## Personal players details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3972973d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import time\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "WIKIDATA_SPARQL_URL = \"https://query.wikidata.org/sparql\"\n",
    "\n",
    "WIKIDATA_HEADERS = {\n",
    "    \"Accept\": \"application/sparql-results+json\",\n",
    "    \"User-Agent\": \"RAG_Football/1.0 (contact: mqt2604@gmail.com)\"\n",
    "}\n",
    "\n",
    "\n",
    "WBSEARCH_URL = \"https://www.wikidata.org/w/api.php\"\n",
    "\n",
    "def resolve_names_to_qids(names: list[str]) -> dict[str, list[str]]:\n",
    "    out = {}\n",
    "    for name in names:\n",
    "        if not name or not name.strip():\n",
    "            continue\n",
    "        params = {\n",
    "            \"action\": \"wbsearchentities\",\n",
    "            \"search\": name,\n",
    "            \"language\": \"en\",\n",
    "            \"type\": \"item\",\n",
    "            \"limit\": 3,\n",
    "            \"format\": \"json\",\n",
    "        }\n",
    "        attempt = 0\n",
    "        while attempt < 5:\n",
    "            r = requests.get(\n",
    "                WBSEARCH_URL, params=params,\n",
    "                headers={**WIKIDATA_HEADERS, \"Accept-Encoding\": \"gzip\"},\n",
    "                timeout=30\n",
    "            )\n",
    "            if r.status_code in (429, 503):\n",
    "                ra = r.headers.get(\"Retry-After\")\n",
    "                wait_s = int(ra) if ra and ra.isdigit() else (2 ** attempt + 0.5)\n",
    "                time.sleep(wait_s); attempt += 1; continue\n",
    "\n",
    "            r.raise_for_status()\n",
    "            hits = r.json().get(\"search\", [])\n",
    "            qids = [h[\"id\"] for h in hits if \"id\" in h]\n",
    "            key = \" \".join(name.strip().lower().split())\n",
    "            if qids:\n",
    "                out[key] = qids\n",
    "            break\n",
    "        time.sleep(0.3)  # l·ªãch s·ª±\n",
    "    return out\n",
    "\n",
    "\n",
    "def build_props_query_for_qids(qids: list[str]) -> str:\n",
    "    values = \" \".join([f\"wd:{qid}\" for qid in qids])\n",
    "    return f\"\"\"\n",
    "    SELECT DISTINCT ?player ?birthDate ?height ?weight ?countryLabel ?positionLabel ?teamLabel WHERE {{\n",
    "    VALUES ?player {{ {values} }}\n",
    "    ?player wdt:P31 wd:Q5 .              \n",
    "    ?player wdt:P106 wd:Q937857 .    # ngh·ªÅ: c·∫ßu th·ªß b√≥ng ƒë√°    \n",
    "    OPTIONAL {{ ?player wdt:P569 ?birthDate. }}\n",
    "    OPTIONAL {{ ?player wdt:P2048 ?height. }}\n",
    "    OPTIONAL {{ ?player wdt:P2067 ?weight. }}\n",
    "    OPTIONAL {{ ?player wdt:P27 ?country. }}\n",
    "    OPTIONAL {{ ?player wdt:P413 ?position. }}\n",
    "    OPTIONAL {{ ?player wdt:P54 ?team. }}   # th√†nh vi√™n CLB (c·∫£ hi·ªán t·∫°i/l·ªãch s·ª≠)\n",
    "    SERVICE wikibase:label {{ bd:serviceParam wikibase:language \"en\". }}\n",
    "    }}\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def fetch_wikidata_players_batched(names: list[str], qid_batch: int = 80) -> dict:\n",
    "    # Phase A: name -> QIDs\n",
    "    qid_map = resolve_names_to_qids(names)\n",
    "\n",
    "    all_result = {}\n",
    "    # Phase B: QIDs -> properties\n",
    "    all_qids = sorted({qid for qids in qid_map.values() for qid in qids})\n",
    "    for i in range(0, len(all_qids), qid_batch):\n",
    "        qids = all_qids[i:i+qid_batch]\n",
    "        query = build_props_query_for_qids(qids)\n",
    "\n",
    "        # POST + backoff\n",
    "        attempt = 0\n",
    "        while attempt < 5:\n",
    "            try:\n",
    "                resp = requests.post(\n",
    "                    WIKIDATA_SPARQL_URL,\n",
    "                    data={\"query\": query, \"format\": \"json\"},\n",
    "                    headers={**WIKIDATA_HEADERS, \"Accept-Encoding\": \"gzip\"},\n",
    "                    timeout=60,\n",
    "                )\n",
    "                # x·ª≠ l√Ω throttle\n",
    "                if resp.status_code in (429, 503):\n",
    "                    ra = resp.headers.get(\"Retry-After\")\n",
    "                    wait_s = int(ra) if ra and ra.isdigit() else (2 ** attempt + 0.5)\n",
    "                    time.sleep(wait_s)\n",
    "                    attempt += 1\n",
    "                    continue\n",
    "\n",
    "                resp.raise_for_status()\n",
    "                data = resp.json()\n",
    "\n",
    "                # 1) Gom k·∫øt qu·∫£ theo QID\n",
    "                qid_to_rows = {}\n",
    "                qid_teamset = defaultdict(set)  # <‚Äî NEW: gom team theo QID\n",
    "\n",
    "                for row in data.get(\"results\", {}).get(\"bindings\", []):\n",
    "                    qid = row[\"player\"][\"value\"].rsplit(\"/\", 1)[-1]\n",
    "                    rec = {\n",
    "                        \"wikidata_id\": qid,\n",
    "                        \"name\": row.get(\"playerLabel\", {}).get(\"value\"),\n",
    "                        \"birth_date\": row.get(\"birthDate\", {}).get(\"value\"),\n",
    "                        \"height_m\": float(row[\"height\"][\"value\"]) if \"height\" in row else None,\n",
    "                        \"weight_kg\": float(row[\"weight\"][\"value\"]) if \"weight\" in row else None,\n",
    "                        \"nationality\": row.get(\"countryLabel\", {}).get(\"value\"),\n",
    "                        \"position\": row.get(\"positionLabel\", {}).get(\"value\"),\n",
    "                    }\n",
    "                    team = row.get(\"teamLabel\", {}).get(\"value\")\n",
    "                    if team:\n",
    "                        qid_teamset[qid].add(team)  # <‚Äî gom v√†o set theo QID\n",
    "\n",
    "                    qid_to_rows.setdefault(qid, []).append(rec)\n",
    "\n",
    "                # chu·∫©n ho√°: g√°n danh s√°ch team ƒë·∫ßy ƒë·ªß cho m·ªçi rec c·ªßa c√πng QID\n",
    "                for _qid, _rows in qid_to_rows.items():\n",
    "                    teams_list = sorted(qid_teamset[_qid]) if _qid in qid_teamset else []\n",
    "                    for _r in _rows:\n",
    "                        _r[\"teams\"] = teams_list\n",
    "\n",
    "                # 2) Map v·ªÅ t√™n g·ªëc + CH·ªêNG TR√ôNG\n",
    "                for name_key, qids in qid_map.items():\n",
    "                    bucket = all_result.setdefault(name_key, [])\n",
    "                    seen = set((r[\"wikidata_id\"],\n",
    "                                r.get(\"birth_date\"),\n",
    "                                r.get(\"height_m\"),\n",
    "                                r.get(\"weight_kg\"),\n",
    "                                r.get(\"nationality\"),\n",
    "                                r.get(\"position\")) for r in bucket)\n",
    "                    for q in qids:\n",
    "                        for rec in qid_to_rows.get(q, []):\n",
    "                            sig = (rec[\"wikidata_id\"],\n",
    "                                rec.get(\"birth_date\"),\n",
    "                                rec.get(\"height_m\"),\n",
    "                                rec.get(\"weight_kg\"),\n",
    "                                rec.get(\"nationality\"),\n",
    "                                rec.get(\"position\"))\n",
    "                            if sig in seen:\n",
    "                                continue\n",
    "                            seen.add(sig)\n",
    "                            bucket.append(rec)\n",
    "\n",
    "\n",
    "\n",
    "                # l·ªãch s·ª± v·ªõi WDQS: ~ <= 1 req/gi√¢y\n",
    "                time.sleep(1.0)\n",
    "                break\n",
    "            except requests.exceptions.Timeout:\n",
    "                attempt += 1\n",
    "                time.sleep(2 ** attempt)\n",
    "            except Exception as e:\n",
    "                attempt += 1\n",
    "                time.sleep(1.0)\n",
    "        # next batch\n",
    "    return all_result\n",
    "\n",
    "\n",
    "def meters_to_cm(m):\n",
    "    if m is None:\n",
    "        return None\n",
    "    try:\n",
    "        return int(round(float(m) * 100))\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "NAT_MAP = {\n",
    "    \"eng\": \"england\", \"sco\": \"scotland\", \"wal\": \"wales\", \"nir\": \"northern ireland\",\n",
    "    \"usa\": \"united states\", \"kor\": \"south korea\", \"civ\": \"ivory coast\",\n",
    "    \"ned\": \"netherlands\", \"ger\": \"germany\", \"fra\": \"france\", \"esp\": \"spain\",\n",
    "    \"por\": \"portugal\", \"bra\": \"brazil\", \"arg\": \"argentina\", \"uru\": \"uruguay\",\n",
    "}\n",
    "\n",
    "def norm_nat(s: str | None) -> str:\n",
    "    s = _norm(s)\n",
    "    if not s: return \"\"\n",
    "    tok = s.split()[-1]              # FBref/Kaggle ƒë√¥i khi c√≥ 'eng ENG' -> l·∫•y 'eng'\n",
    "    return NAT_MAP.get(tok, s)\n",
    "\n",
    "POS_MAP = {\n",
    "    \"gk\": {\"goalkeeper\"},\n",
    "    \"df\": {\"defender\", \"centre-back\", \"center back\", \"full-back\", \"wing-back\"},\n",
    "    \"mf\": {\"midfielder\", \"defensive midfielder\", \"attacking midfielder\", \"winger\"},\n",
    "    \"fw\": {\"forward\", \"striker\", \"centre-forward\", \"center forward\", \"winger\"},\n",
    "}\n",
    "\n",
    "def pos_match(ent_pos: str, wd_pos: str) -> bool:\n",
    "    ep = _norm(ent_pos)\n",
    "    wp = _norm(wd_pos)\n",
    "    if not ep or not wp: return False\n",
    "    codes = [t for t in ep.replace(\"/\", \",\").split(\",\") if t]\n",
    "    for code in codes:\n",
    "        code = code.strip()\n",
    "        vocab = POS_MAP.get(code, {code})\n",
    "        if any(v in wp for v in vocab):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def _norm(s: str | None) -> str:\n",
    "    return \" \".join(str(s).strip().lower().split()) if s else \"\"\n",
    "\n",
    "def pick_wikidata_candidate(entity: dict, candidates: list[dict]) -> dict | None:\n",
    "    ident = entity.get(\"identity\", {}) or {}\n",
    "    ent_nat = norm_nat(ident.get(\"nationality\"))\n",
    "    ent_pos = _norm(ident.get(\"position\"))\n",
    "\n",
    "    best = None\n",
    "    best_score = -1\n",
    "\n",
    "    for c in candidates:\n",
    "        score = 0\n",
    "        c_nat = _norm(c.get(\"nationality\"))\n",
    "        c_pos = _norm(c.get(\"position\"))\n",
    "\n",
    "        # match qu·ªëc t·ªãch (n·ªõi l·ªèng: uk vs england/wales/scotland/nir)\n",
    "        if ent_nat and c_nat:\n",
    "            if ent_nat in c_nat or c_nat in ent_nat:\n",
    "                score += 1\n",
    "            elif c_nat == \"united kingdom\" and ent_nat in {\"england\",\"scotland\",\"wales\",\"northern ireland\"}:\n",
    "                score += 1\n",
    "\n",
    "        # match v·ªã tr√≠ (map 'fw/df/mf/gk' sang nh√£n Wikidata)\n",
    "        if ent_pos and c_pos and pos_match(ent_pos, c_pos):\n",
    "            score += 1\n",
    "\n",
    "        # ∆∞u ti√™n c√≥ ng√†y sinh (·ªïn ƒë·ªãnh h∆°n)\n",
    "        if c.get(\"birth_date\"):\n",
    "            score += 0.2\n",
    "\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best = c\n",
    "\n",
    "    # ch·∫•p nh·∫≠n n·∫øu c√≥ √≠t nh·∫•t 1 ti√™u ch√≠ kh·ªõp\n",
    "    return best if best_score >= 1 else None\n",
    "\n",
    "\n",
    "def enrich_metadata_with_wikidata(metadata_entities: list[dict]) -> list[dict]:\n",
    "    # 1) Query candidates theo unique name (batch)\n",
    "    unique_names = sorted({e[\"name\"] for e in metadata_entities if e.get(\"name\")})\n",
    "    print(f\"Querying Wikidata for {len(unique_names)} unique names...\")\n",
    "    wikidata_map = fetch_wikidata_players_batched(unique_names, qid_batch=80)\n",
    "    print(f\"Wikidata returned labels for {len(wikidata_map)} names\")\n",
    "\n",
    "    enriched = 0\n",
    "    ambiguous = 0\n",
    "\n",
    "    # 2) Duy·ªát t·ª´ng entity (1‚Äì1 theo entity_id)\n",
    "    for e in metadata_entities:\n",
    "        name_key = _norm(e.get(\"name\"))\n",
    "        if not name_key:\n",
    "            continue\n",
    "\n",
    "        candidates = wikidata_map.get(name_key)\n",
    "        if not candidates:\n",
    "            continue\n",
    "\n",
    "        wd = pick_wikidata_candidate(e, candidates)\n",
    "        if not wd:\n",
    "            ambiguous += 1\n",
    "            continue\n",
    "\n",
    "        ident = e.setdefault(\"identity\", {})\n",
    "\n",
    "        # Fill fields n·∫øu c√≤n tr·ªëng\n",
    "        if wd.get(\"birth_date\") and not ident.get(\"birth_year\"):\n",
    "            try:\n",
    "                ident[\"birth_year\"] = int(wd[\"birth_date\"][:4])\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "        h_cm = meters_to_cm(wd.get(\"height_m\"))\n",
    "        if h_cm and not ident.get(\"height_cm\"):\n",
    "            ident[\"height_cm\"] = h_cm\n",
    "\n",
    "        if wd.get(\"weight_kg\") and not ident.get(\"weight_kg\"):\n",
    "            try:\n",
    "                ident[\"weight_kg\"] = int(round(float(wd[\"weight_kg\"])))\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "        wd_nat = wd.get(\"nationality\")\n",
    "        if wd_nat and not ident.get(\"nationality\"):\n",
    "            ident[\"nationality\"] = wd_nat\n",
    "\n",
    "        wd_pos = wd.get(\"position\")\n",
    "        if wd_pos and not ident.get(\"position\"):\n",
    "            ident[\"position\"] = _norm(wd_pos)\n",
    "\n",
    "        # G·∫Øn wikidata_id ri√™ng cho entity n√†y\n",
    "        e.setdefault(\"external_ids\", {})[\"wikidata\"] = wd[\"wikidata_id\"]\n",
    "        e.setdefault(\"sources\", [])\n",
    "        if \"wikidata\" not in e[\"sources\"]:\n",
    "            e[\"sources\"].append(\"wikidata\")\n",
    "\n",
    "        enriched += 1\n",
    "\n",
    "    print(f\"Enriched {enriched} / {len(metadata_entities)} entities with Wikidata\")\n",
    "    print(f\"Skipped {ambiguous} entities due to ambiguous or low-confidence matches\")\n",
    "    return metadata_entities\n",
    "\n",
    "\n",
    "metadata_entities = []\n",
    "with open(\"/content/drive/MyDrive/players_metadata_placeholder_2024_2025.jsonl\", \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        metadata_entities.append(json.loads(line))\n",
    "\n",
    "metadata_entities = enrich_metadata_with_wikidata(metadata_entities)\n",
    "\n",
    "output_path_wd = \"/content/drive/MyDrive/players_metadata_wikidata_2024_2025.jsonl\"\n",
    "with open(output_path_wd, \"w\", encoding=\"utf-8\") as f:\n",
    "    for e in metadata_entities:\n",
    "        f.write(json.dumps(e, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "print(f\"Saved Wikidata-enriched metadata to {output_path_wd}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a2a828",
   "metadata": {},
   "source": [
    "## merge career with available metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c335c12f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 8211 career stats\n",
      "Loaded 2854 metadata entities\n",
      "\n",
      "‚úÖ Merged 2854 complete player entities\n",
      "üìÅ Saved to: data/players/players_complete_metadata.jsonl\n",
      "\n",
      "üéØ Harry Kane Big 5 career totals:\n",
      "  Goals: 246\n",
      "  Assists: 52\n",
      "  Matches: 338\n",
      "\n",
      "üéØ Harry Kane complete career totals (placeholder):\n",
      "  Goals: None (ch∆∞a c√≥ data)\n",
      "  Assists: None (ch∆∞a c√≥ data)\n"
     ]
    }
   ],
   "source": [
    "# Merge career stats v·ªõi metadata placeholder\n",
    "import json\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Load career stats\n",
    "with open(\"data/players/career_stats.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    career_stats = json.load(f)\n",
    "\n",
    "metadata_entities = []\n",
    "with open(\"data/players/players_metadata_wikidata_2024_2025.jsonl\", \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        if line.strip():\n",
    "            metadata_entities.append(json.loads(line))\n",
    "\n",
    "print(f\"Loaded {len(career_stats)} career stats\")\n",
    "print(f\"Loaded {len(metadata_entities)} metadata entities\")\n",
    "\n",
    "# Merge function\n",
    "def merge_career_with_metadata(career_stats, metadata_entities):\n",
    "    merged = []\n",
    "    \n",
    "    # Create lookup dict for career stats\n",
    "    career_lookup = {}\n",
    "    for player_name, career_data in career_stats.items():\n",
    "        norm_name = player_name.lower().strip()\n",
    "        career_lookup[norm_name] = career_data\n",
    "    \n",
    "    # Merge with metadata\n",
    "    for entity in metadata_entities:\n",
    "        player_name = entity[\"name\"]\n",
    "        norm_name = player_name.lower().strip()\n",
    "        \n",
    "        if norm_name in career_lookup:\n",
    "            # Merge career stats\n",
    "            entity[\"career_stats\"] = career_lookup[norm_name]\n",
    "            \n",
    "            # Update career totals\n",
    "            total_goals = sum(season[\"goals\"] for season in career_lookup[norm_name])\n",
    "            total_assists = sum(season[\"assists\"] for season in career_lookup[norm_name])\n",
    "            total_matches = sum(season[\"matches\"] for season in career_lookup[norm_name])\n",
    "            total_minutes = sum(season[\"minutes\"] for season in career_lookup[norm_name])\n",
    "            \n",
    "            entity[\"big5_career_totals\"] = {\n",
    "                \"total_big5_goals\": total_goals,\n",
    "                \"total_big5_assists\": total_assists,\n",
    "                \"total_big5_matches\": total_matches,\n",
    "                \"total_big5_minutes\": total_minutes,\n",
    "                \"coverage\": \"Big 5 European Leagues (2014-2015 to 2024-2025)\",\n",
    "                \"note\": \"Ch·ªâ bao g·ªìm th·ªùi gian ch∆°i trong Big 5 leagues, kh√¥ng ph·∫£i to√†n b·ªô s·ª± nghi·ªáp\"\n",
    "                }\n",
    "            \n",
    "            \n",
    "            entity[\"sources\"].append(\"soccerdata\")\n",
    "        \n",
    "        merged.append(entity)\n",
    "    \n",
    "    return merged\n",
    "\n",
    "# Execute merge\n",
    "merged_entities = merge_career_with_metadata(career_stats, metadata_entities)\n",
    "\n",
    "# Save merged data\n",
    "output_path = \"data/players/players_complete_metadata.jsonl\"\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    for entity in merged_entities:\n",
    "        f.write(json.dumps(entity, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "print(f\"\\n‚úÖ Merged {len(merged_entities)} complete player entities\")\n",
    "print(f\"üìÅ Saved to: {output_path}\")\n",
    "\n",
    "# Test v·ªõi Harry Kane\n",
    "kane_entity = next((e for e in merged_entities if \"harry kane\" in e[\"name\"]), None)\n",
    "if kane_entity:\n",
    "    print(f\"\\nüéØ Harry Kane Big 5 career totals:\")\n",
    "    print(f\"  Goals: {kane_entity['big5_career_totals']['total_big5_goals']}\")\n",
    "    print(f\"  Assists: {kane_entity['big5_career_totals']['total_big5_assists']}\")\n",
    "    print(f\"  Matches: {kane_entity['big5_career_totals']['total_big5_matches']}\")\n",
    "    \n",
    "    # Show career_totals v·∫´n l√† placeholder\n",
    "    print(f\"\\nüéØ Harry Kane complete career totals (placeholder):\")\n",
    "    print(f\"  Goals: {kane_entity['career_totals']['total_career_goals']} (ch∆∞a c√≥ data)\")\n",
    "    print(f\"  Assists: {kane_entity['career_totals']['total_career_assists']} (ch∆∞a c√≥ data)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
